{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import openpyxl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ISO8601                    deFecha  \\\n",
      "0  2022-12-01T23:59:59+01:00   jueves, 1 de dic de 2022   \n",
      "1  2022-12-02T23:59:59+01:00  viernes, 2 de dic de 2022   \n",
      "2  2022-12-03T23:59:59+01:00   sábado, 3 de dic de 2022   \n",
      "3  2022-12-04T23:59:59+01:00  domingo, 4 de dic de 2022   \n",
      "4  2022-12-05T23:59:59+01:00    lunes, 5 de dic de 2022   \n",
      "\n",
      "                      aFecha         horaDedormir    horaDedespertarse  \\\n",
      "0   jueves, 1 de dic de 2022  2022-12-01 00:30:00  2022-12-01 08:30:00   \n",
      "1  viernes, 2 de dic de 2022  2022-12-02 01:30:00  2022-12-02 09:15:00   \n",
      "2   sábado, 3 de dic de 2022  2022-12-03 01:47:00  2022-12-03 09:44:00   \n",
      "3  domingo, 4 de dic de 2022  2022-12-04 00:45:00  2022-12-04 13:45:00   \n",
      "4    lunes, 5 de dic de 2022  2022-12-05 01:42:00  2022-12-05 06:30:00   \n",
      "\n",
      "     enCama despierto seDurmióEn  sesiones   dormido  ... VFCdormido  \\\n",
      "0  08:35:00  00:10:00   00:00:00         2  08:25:00  ...       44.0   \n",
      "1  07:45:00  00:15:00        NaN         1  07:30:00  ...        NaN   \n",
      "2  07:57:00  00:40:00   00:00:00         1  07:17:00  ...       58.0   \n",
      "3  13:00:00  03:00:00        NaN         1  10:00:00  ...        NaN   \n",
      "4  04:48:00  00:00:00   00:00:00         1  04:48:00  ...       50.0   \n",
      "\n",
      "   mediaVFCdormido7días  mediaSatOx mínSatOx máxSatOx mediaResp mínResp  \\\n",
      "0                  52.0        96.4     94.0    100.0      13.5    11.0   \n",
      "1                   NaN         NaN      NaN      NaN       NaN     NaN   \n",
      "2                  51.0        97.0     97.0     97.0       NaN     NaN   \n",
      "3                   NaN         NaN      NaN      NaN       NaN     NaN   \n",
      "4                  51.0        97.7     96.0    100.0      13.6    11.0   \n",
      "\n",
      "   máxResp  etiquetas  notas  \n",
      "0     16.5        NaN    NaN  \n",
      "1      NaN        NaN    NaN  \n",
      "2      NaN        NaN    NaN  \n",
      "3      NaN        NaN    NaN  \n",
      "4     17.0        NaN    NaN  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "0    2022-12-01\n",
      "1    2022-12-02\n",
      "2    2022-12-03\n",
      "3    2022-12-04\n",
      "4    2022-12-05\n",
      "Name: Date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Loading the sleep data\n",
    "sleep_Data = pd.read_csv('AutoSleep-data.csv')\n",
    "print(sleep_Data.head())\n",
    "# Creating a new column called 'Date' getting only the date from ISO8601 column\n",
    "sleep_Data['Date'] = sleep_Data['ISO8601'].str.split('T').str[0]\n",
    "# showing Date column head\n",
    "print(sleep_Data['Date'].head())\n",
    "# Creating a new dataframe with only the Date and Dormido columns\n",
    "sleep_Data = sleep_Data[['Date', 'dormido']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date Weight (kg)  Fat Percent Calories (kcal) Protein (g) Fat (g)  \\\n",
      "5 2023-01-02        88.1         27.1             NaN         NaN     NaN   \n",
      "6 2023-01-03       87.25         26.8             NaN         NaN     NaN   \n",
      "7 2023-01-04       87.25         26.7             NaN         NaN     NaN   \n",
      "8 2023-01-05   86.800003         26.4             NaN         NaN     NaN   \n",
      "9 2023-01-06        86.3         26.3             NaN         NaN     NaN   \n",
      "\n",
      "  Carbs (g)  Visual Body Fat Assessment  Expenditure  Trend Weight (kg)  \\\n",
      "5       NaN                         NaN          NaN                NaN   \n",
      "6       NaN                         NaN          NaN                NaN   \n",
      "7       NaN                         NaN          NaN                NaN   \n",
      "8       NaN                         NaN          NaN                NaN   \n",
      "9       NaN                         NaN          NaN                NaN   \n",
      "\n",
      "  Target Calories (kcal) Target Protein (g) Target Fat (g) Target Carbs (g)  \n",
      "5                    NaN                NaN            NaN              NaN  \n",
      "6                    NaN                NaN            NaN              NaN  \n",
      "7                    NaN                NaN            NaN              NaN  \n",
      "8                    NaN                NaN            NaN              NaN  \n",
      "9                    NaN                NaN            NaN              NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the excel file into a dictionary of dataframes, with sheet names as keys\n",
    "xl_file = pd.read_excel(\"MacroFactor-data.xlsx\", sheet_name=None)\n",
    "\n",
    "# Create an empty list to store the filtered sheets\n",
    "filtered_sheets = []\n",
    "\n",
    "# Loop through each sheet in the dictionary\n",
    "for sheet_name, sheet_df in xl_file.items():\n",
    "    # Check if the \"Date\" column exists in the current sheet\n",
    "    if \"Date\" in sheet_df.columns:\n",
    "        # Check if the \"Date\" column contains any non-null values\n",
    "        if sheet_df[\"Date\"].notnull().any():\n",
    "            filtered_sheets.append(sheet_df)\n",
    "\n",
    "# Combine the filtered sheets into a single dataframe\n",
    "df = pd.concat(filtered_sheets)\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "# Drop dates that are earlier than 2023\n",
    "df = df[df['Date'] > '2023-01-01']\n",
    "# Show df head\n",
    "print(df.head())\n",
    "# Convert Datetime to date\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "# save dataframe to excel file\n",
    "df.to_excel('MacroFactor-data_test.xlsx', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "         Date Weight (kg)  Fat Percent Calories (kcal) Protein (g) Fat (g)  \\\n",
      "5  2023-01-02        88.1         27.1             NaN         NaN     NaN   \n",
      "6  2023-01-03       87.25         26.8             NaN         NaN     NaN   \n",
      "7  2023-01-04       87.25         26.7             NaN         NaN     NaN   \n",
      "8  2023-01-05   86.800003         26.4             NaN         NaN     NaN   \n",
      "9  2023-01-06        86.3         26.3             NaN         NaN     NaN   \n",
      "\n",
      "  Carbs (g)  Visual Body Fat Assessment  Expenditure  Trend Weight (kg)  \\\n",
      "5       NaN                         NaN          NaN                NaN   \n",
      "6       NaN                         NaN          NaN                NaN   \n",
      "7       NaN                         NaN          NaN                NaN   \n",
      "8       NaN                         NaN          NaN                NaN   \n",
      "9       NaN                         NaN          NaN                NaN   \n",
      "\n",
      "  Target Calories (kcal) Target Protein (g) Target Fat (g) Target Carbs (g)  \n",
      "5                    NaN                NaN            NaN              NaN  \n",
      "6                    NaN                NaN            NaN              NaN  \n",
      "7                    NaN                NaN            NaN              NaN  \n",
      "8                    NaN                NaN            NaN              NaN  \n",
      "9                    NaN                NaN            NaN              NaN  \n",
      "         Date Weight (kg)  Fat Percent Calories (kcal) Protein (g) Fat (g)  \\\n",
      "5  2023-01-02        88.1         27.1             NaN         NaN     NaN   \n",
      "6  2023-01-03       87.25         26.8             NaN         NaN     NaN   \n",
      "7  2023-01-04       87.25         26.7             NaN         NaN     NaN   \n",
      "8  2023-01-05   86.800003         26.4             NaN         NaN     NaN   \n",
      "9  2023-01-06        86.3         26.3             NaN         NaN     NaN   \n",
      "\n",
      "  Carbs (g)  Visual Body Fat Assessment  Expenditure  Trend Weight (kg)  \\\n",
      "5       NaN                         NaN          NaN                NaN   \n",
      "6       NaN                         NaN          NaN                NaN   \n",
      "7       NaN                         NaN          NaN                NaN   \n",
      "8       NaN                         NaN          NaN                NaN   \n",
      "9       NaN                         NaN          NaN                NaN   \n",
      "\n",
      "  Target Calories (kcal) Target Protein (g) Target Fat (g) Target Carbs (g)  \n",
      "5                    NaN                NaN            NaN              NaN  \n",
      "6                    NaN                NaN            NaN              NaN  \n",
      "7                    NaN                NaN            NaN              NaN  \n",
      "8                    NaN                NaN            NaN              NaN  \n",
      "9                    NaN                NaN            NaN              NaN  \n",
      "object\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Print sleep date date type\n",
    "print(type(sleep_Data['Date'][0]))\n",
    "# Change Dattype to date\n",
    "sleep_Data['Date'] = pd.to_datetime(sleep_Data['Date']).dt.date\n",
    "# print df head\n",
    "print(df.head())\n",
    "# change df date type to date\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = df['Date'].dt.date\n",
    "# Print df date type\n",
    "# show df head\n",
    "print(df.head())\n",
    "df.shape\n",
    "print(df['Date'].dtype)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df['Date'].dtype)\n",
    "# # Combine both dataframes based on Date\n",
    "# combined_Data = pd.merge(sleep_Data, df, on='Date')\n",
    "# # Show combined_Data head\n",
    "# print(combined_Data.head())\n",
    "sleep_Data['Date'] = pd.to_datetime(sleep_Data['Date'])\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date   dormido Calories (kcal) Target Calories (kcal)\n",
      "2  2023-01-02  06:23:00            2091                   1795\n",
      "5  2023-01-03  08:14:00            1985                   1795\n",
      "8  2023-01-04  07:04:00            1886                   1795\n",
      "11 2023-01-05  05:39:00            1878                   1795\n",
      "14 2023-01-06  09:05:00            2953                   1795\n",
      "17 2023-01-07  07:10:00            2177                   1795\n",
      "20 2023-01-08  07:15:00            3345                   1795\n",
      "23 2023-01-09  07:33:00            1727                   1681\n",
      "26 2023-01-10  08:34:00            1447                   1681\n",
      "29 2023-01-11  08:04:00            2303                   1681\n",
      "32 2023-01-12  05:44:00            1904                   1681\n",
      "35 2023-01-13  07:17:00            1659                   1681\n",
      "38 2023-01-14  07:21:00            2045                   1681\n",
      "41 2023-01-15  08:45:00            1957                   1681\n",
      "44 2023-01-16  05:01:00            2004                   1530\n",
      "47 2023-01-18  07:31:00            1672                   1530\n",
      "50 2023-01-19  08:03:00            1955                   1530\n",
      "53 2023-01-20  06:02:00            1766                   1530\n",
      "56 2023-01-21  07:54:00            1825                   1530\n",
      "59 2023-01-22  07:32:00            2126                   1530\n"
     ]
    }
   ],
   "source": [
    "# Now we merge both datasets based on the Date column\n",
    "merged_df = pd.merge(sleep_Data, df, on='Date', how='inner')\n",
    "# We merge date so there are no duplicates\n",
    "\n",
    "# We only keep Date, dormido, Calories and Target Calories\n",
    "merged_df = merged_df[['Date', 'dormido', 'Calories (kcal)', 'Target Calories (kcal)']]\n",
    "\n",
    "# Now we drop all rows with decimal values in Calories\n",
    "merged_df = merged_df[merged_df['Calories (kcal)'] % 1 == 0]\n",
    "# Same with target calories\n",
    "final_df = merged_df[merged_df['Target Calories (kcal)'] % 1 == 0]\n",
    "print(final_df.head(20))\n",
    "# Next, we'll use the combine_first() method to keep the non-NaN data\n",
    "# final_df = merged_df['dormido'].combine_first(merged_df['Calories (kcal)'])\n",
    "# final_df = final_df.to_frame().merge(merged_df['Calories (kcal)'], left_index=True, right_index=True)\n",
    "# final_df = final_df.reset_index()\n",
    "\n",
    "# # Show combined_Data head\n",
    "# print(final_df.head(20))\n",
    "# Using combine_first() to fill in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date   dormido  Calories (kcal)  Target Calories (kcal)  eat_more\n",
      "2  2023-01-02  6.383333             2091                    1795         0\n",
      "5  2023-01-03  8.233333             1985                    1795         0\n",
      "8  2023-01-04  7.066667             1886                    1795         0\n",
      "11 2023-01-05  5.650000             1878                    1795         0\n",
      "14 2023-01-06  9.083333             2953                    1795         1\n",
      "17 2023-01-07  7.166667             2177                    1795         0\n",
      "20 2023-01-08  7.250000             3345                    1795         1\n",
      "23 2023-01-09  7.550000             1727                    1681         0\n",
      "26 2023-01-10  8.566667             1447                    1681         0\n",
      "29 2023-01-11  8.066667             2303                    1681         1\n",
      "32 2023-01-12  5.733333             1904                    1681         0\n",
      "35 2023-01-13  7.283333             1659                    1681         0\n",
      "38 2023-01-14  7.350000             2045                    1681         0\n",
      "41 2023-01-15  8.750000             1957                    1681         0\n",
      "44 2023-01-16  5.016667             2004                    1530         0\n",
      "47 2023-01-18  7.516667             1672                    1530         0\n",
      "50 2023-01-19  8.050000             1955                    1530         0\n",
      "53 2023-01-20  6.033333             1766                    1530         0\n",
      "56 2023-01-21  7.900000             1825                    1530         0\n",
      "59 2023-01-22  7.533333             2126                    1530         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo\\AppData\\Local\\Temp\\ipykernel_14968\\2066261368.py:2: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  final_df.fillna(final_df.mean(), inplace=True)\n",
      "C:\\Users\\Pablo\\AppData\\Local\\Temp\\ipykernel_14968\\2066261368.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  final_df.fillna(final_df.mean(), inplace=True)\n",
      "C:\\Users\\Pablo\\AppData\\Local\\Temp\\ipykernel_14968\\2066261368.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df.fillna(final_df.mean(), inplace=True)\n",
      "C:\\Users\\Pablo\\AppData\\Local\\Temp\\ipykernel_14968\\2066261368.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['dormido'] = final_df['dormido'].str.split(':').apply(lambda x: (int(x[0]) + int(x[1]) / 60))\n",
      "C:\\Users\\Pablo\\AppData\\Local\\Temp\\ipykernel_14968\\2066261368.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['eat_more'] = np.where(final_df['Calories (kcal)'] - final_df['Target Calories (kcal)'] >= 500, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# handling missing values\n",
    "final_df.fillna(final_df.mean(), inplace=True)\n",
    "# Convertime \"dormido\" time to minutes\n",
    "final_df['dormido'] = final_df['dormido'].str.split(':').apply(lambda x: (int(x[0]) + int(x[1]) / 60))\n",
    "# creating a new target variable\n",
    "final_df['eat_more'] = np.where(final_df['Calories (kcal)'] - final_df['Target Calories (kcal)'] >= 500, 1, 0)\n",
    "# remove last row\n",
    "final_df = final_df[:-1]\n",
    "print(final_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df[['dormido', 'Target Calories (kcal)']], final_df['eat_more'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# making predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0]\n",
      "You will not overeat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pablo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# making predictions on new data\n",
    "new_data = np.array([[7, 1500]])\n",
    "prediction = model.predict(new_data)\n",
    "# if prediction is 1 change it to \"You will overeat!\"\n",
    "if prediction == 1:\n",
    "    prediction_verbose = \"You will overeat!\"\n",
    "else:\n",
    "    prediction_verbose = \"You will not overeat!\"\n",
    "print('Prediction:', prediction)\n",
    "print(prediction_verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your chance of overeating today and exceeding 1381 is 0.3\n"
     ]
    }
   ],
   "source": [
    "# Calculate get the target calories of last record\n",
    "target_calories = final_df['Target Calories (kcal)'].iloc[-1]\n",
    "# get the coefficients of the model\n",
    "coefficients = model.coef_\n",
    "# calculate the intercept\n",
    "intercept = model.intercept_\n",
    "# calculate the probability of overeating\n",
    "probability = 1 / (1 + np.exp(-(coefficients[0][0] * 7 + coefficients[0][1] * target_calories + intercept)))\n",
    "# delete [] from probability\n",
    "probability = probability[0]\n",
    "# round to 2 decimals\n",
    "probability = round(probability, 2)\n",
    "# multiply by 100 to get percentage\n",
    "probability = probability * 100\n",
    "# add % to probability\n",
    "probability = str(probability) + '%'\n",
    "print('Your chance of overeating today and exceeding ' + str(target_calories) + ' ' + 'is ' + str(probability))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb63a77499ed5899fffa71b49f0fc3f4df2c625891c3993c985b13a523c87e61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
